{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler, Subset, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 933120000000\n",
    "\n",
    "LR = 5e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 4\n",
    "N_SPLITS = 5\n",
    "N_ACCUMULATE = 16\n",
    "MODEL_NAME = 'resnext50_32x4d.a1_in1k'\n",
    "Image_size = 512\n",
    "WEIGHT_DECAY = 1e-4\n",
    "num_classes = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# //\n",
    "# //                       _oo0oo_\n",
    "# //                      o8888888o\n",
    "# //                      88\" . \"88\n",
    "# //                      (| -_- |)\n",
    "# //                      0\\  =  /0\n",
    "# //                    ___/`---'\\___\n",
    "# //                  .' \\\\|     |// '.\n",
    "# //                 / \\\\|||  :  |||// \\\n",
    "# //                / _||||| -:- |||||- \\\n",
    "# //               |   | \\\\\\  -  /// |   |\n",
    "# //               | \\_|  ''\\---/''  |_/ |\n",
    "# //               \\  .-\\__  '-'  ___/-. /\n",
    "# //             ___'. .'  /--.--\\  `. .'___\n",
    "# //          .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
    "# //         | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
    "# //         \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
    "# //     =====`-.____`.___ \\_____/___.-`___.-'=====\n",
    "# //                       `=---='\n",
    "# //\n",
    "# //\n",
    "# //     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "# //\n",
    "# //               佛祖保佑         永无BUG\n",
    "# //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (430, 512, 512, 3)\n",
      "Y_train shape: (430,)\n"
     ]
    }
   ],
   "source": [
    "# Load the saved .npy files\n",
    "X_train_path = '/kaggle/input/cs640-numpy/X_train.npy'  # replace with the actual path\n",
    "Y_train_path = '/kaggle/input/cs640-numpy/Y_train.npy'  # replace with the actual path\n",
    "\n",
    "# Check if the files exist before loading them\n",
    "if os.path.exists(X_train_path) and os.path.exists(Y_train_path):\n",
    "    X_train = np.load(X_train_path)\n",
    "    Y_train = np.load(Y_train_path)\n",
    "else:\n",
    "    print(\"Files not found. Please check the paths.\")\n",
    "\n",
    "# Verify the shape of arrays\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "X_train_tensor = torch.tensor(X_train).float()\n",
    "Y_train_tensor = torch.from_numpy(Y_train).long()  # assume Y_train contains integer class labels\n",
    "plt.imshow(X_train_tensor[0]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = X_train_tensor.view(-1, Image_size, Image_size, 3)\n",
    "dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "# Split the dataset into a training set and a validation set\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(X_train)),\n",
    "    test_size=0.2,  # reserve 20% for validation\n",
    "    random_state=43,  # guarantee repeatability\n",
    "    stratify=Y_train  # keep data distribution consistent\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "val_dataset = Subset(dataset, val_idx)\n",
    "\n",
    "train_labels = [dataset.tensors[1][i].item() for i in train_idx]\n",
    "val_labels = [dataset.tensors[1][i].item() for i in val_idx]\n",
    "\n",
    "train_images = [dataset[i][0] for i in train_idx]\n",
    "val_images = [dataset[i][0] for i in val_idx]\n",
    "\n",
    "plt.imshow(train_images[0]/255)\n",
    "plt.show()\n",
    "print(train_images[0].shape)\n",
    "\n",
    "Y_train = np.array(Y_train)  # convert to numpy array if not already\n",
    "class_sample_count = np.array([len(np.where(Y_train[train_idx] == t)[0]) for t in np.unique(Y_train[train_idx])])\n",
    "\n",
    "weights = 1. / class_sample_count\n",
    "samples_weights = np.array([weights[t] for t in Y_train[train_idx]])\n",
    "\n",
    "# Convert to a PyTorch tensor\n",
    "samples_weights = torch.from_numpy(samples_weights)\n",
    "samples_weights = samples_weights.double()\n",
    "\n",
    "# Create a sampler for weighted sampling\n",
    "sampler = WeightedRandomSampler(samples_weights, len(samples_weights))\n",
    "\n",
    "# Create data loaders for training and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(len(np.unique(Y_train)))\n",
    "\n",
    "first_batch_images, first_batch_labels = next(iter(train_loader))\n",
    "\n",
    "plt.imshow(first_batch_images[0]/255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(), \n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    # transforms.CenterCrop((224, 224)),  \n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Display the transformation\n",
    "for images, labels in train_loader:\n",
    "    print(images.shape)\n",
    "    images = images/255\n",
    "    images = images.permute(0, 3, 1, 2)\n",
    "    enhanced_image = image_transforms(images)\n",
    "    print(images.shape)\n",
    "    enhanced_image = enhanced_image.permute(0, 2, 3, 1)\n",
    "    plt.imshow(enhanced_image[0])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs, device, patience=18):\n",
    "    model.to(device)\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_balanced_acc': [], 'val_balanced_acc': []}\n",
    "\n",
    "    best_val_acc = 0.0  # keep track of it\n",
    "    best_val_loss = float('inf')  # keep track of it if needed\n",
    "    epochs_no_improve = 0  # use early-stopping strategy\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_preds = []\n",
    "        train_targets = []\n",
    "\n",
    "        # Display the training process\n",
    "        train_loop = tqdm(train_loader, position=0, leave=True)\n",
    "        for batch_index, (inputs, labels) in enumerate(train_loop):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs = inputs/255\n",
    "            inputs = inputs.permute(0, 3, 1, 2)\n",
    "            inputs = image_transforms(inputs)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Update gradients after every N_ACCUMULATE batches\n",
    "            if (batch_index + 1) % N_ACCUMULATE == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Record training loss and accuracy\n",
    "            train_loss += loss.item() # accumulated\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            train_loop.set_description(f\"Epoch [{epoch + 1}/{epochs}]\")\n",
    "            train_preds.extend(predicted.view(-1).cpu().numpy())\n",
    "            train_targets.extend(labels.view(-1).cpu().numpy())\n",
    "        \n",
    "        # Make sure the last accumulated gradient is also updated\n",
    "        if len(train_loader) % N_ACCUMULATE != 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Complete the validation process\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs/255\n",
    "                inputs = inputs.permute(0, 3, 1, 2)\n",
    "                inputs = image_transforms(inputs)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_preds.extend(predicted.view(-1).cpu().numpy())\n",
    "                val_targets.extend(labels.view(-1).cpu().numpy())\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        train_balanced_acc = balanced_accuracy_score(train_targets, train_preds)\n",
    "        val_balanced_acc = balanced_accuracy_score(val_targets, val_preds)\n",
    "        scheduler.step(val_balanced_acc)\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_balanced_acc'].append(train_balanced_acc)\n",
    "        history['val_balanced_acc'].append(val_balanced_acc)\n",
    "        \n",
    "        if val_balanced_acc > best_val_acc:\n",
    "            best_val_acc = val_balanced_acc\n",
    "            epochs_no_improve = 0  # reset\n",
    "            torch.save(model.state_dict(), f'model_checkpoint.pth')\n",
    "            print(f\"Checkpoint saved at epoch {epoch + 1}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in validation loss for {epochs_no_improve} consecutive epochs.\")\n",
    "\n",
    "            # Stop the training process if the tolerance is reached\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "        # Print info of each epoch\n",
    "        print(f\"**Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Train Balanced Acc: {train_balanced_acc:.4f}, Val Loss: {val_loss:.4f}, Val Balanced Acc: {val_balanced_acc:.4f}\")\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot_metrics(history):\n",
    "    actual_epochs = len(history['train_loss']) \n",
    "    epochs_range = range(1, actual_epochs + 1)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, history['train_loss'], label='Train Loss')\n",
    "    plt.plot(epochs_range, history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, history['train_balanced_acc'], label='Train Accuracy')\n",
    "    plt.plot(epochs_range, history['val_balanced_acc'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        # Load a pre-trained model without the classifier\n",
    "        self.base_model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=0)\n",
    "        \n",
    "        # Freeze all parameters of the pre-trained model\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Get the number of features with the classifier removed\n",
    "        features_num = self.base_model.num_features\n",
    "        \n",
    "        # Add custom layers\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(features_num)\n",
    "        # Add several fully connected layers\n",
    "        self.fc1 = nn.Linear(features_num, features_num // 2)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(features_num // 2)\n",
    "        self.fc2 = nn.Linear(features_num // 2, features_num // 4)\n",
    "        self.batch_norm3 = nn.BatchNorm1d(features_num // 4)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.classifier = nn.Linear(features_num // 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model.forward_features(x) # features from the base model\n",
    "        \n",
    "        x = self.global_avg_pool(x).view(x.size(0), -1) # global average pooling\n",
    "        \n",
    "        x = self.batch_norm1(x) # batch normalization\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "# Get parameters of the classifier only \n",
    "# since parameters of the pre-trained model are frozen\n",
    "def get_all_layers(module):\n",
    "    for layer in module.children():\n",
    "        if list(layer.children()):  # fetch its children if it is a nested module\n",
    "            yield from get_all_layers(layer)\n",
    "        else:\n",
    "            yield layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the custom model\n",
    "# model = CustomEfficientNet(num_classes=5, dropout_rate=0.2)\n",
    "\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=5)\n",
    "\n",
    "# Get all layers as a list\n",
    "# all_layers = list(get_all_layers(model.base_model))\n",
    "\n",
    "# Compute the number of layers to unfreeze (e.g., the latter half of the model's layers)\n",
    "# layers_to_unfreeze = len(all_layers) // 2\n",
    "\n",
    "# Unfreeze the latter half of the layers\n",
    "# for layer in all_layers[-layers_to_unfreeze:]:\n",
    "#     for param in layer.parameters():\n",
    "#         param.requires_grad = False\n",
    "\n",
    "weights = torch.tensor(weights, dtype=torch.float32)\n",
    "print(weights)\n",
    "\n",
    "# Create a weighted CrossEntropyLoss\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "# Define an optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=4, verbose=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\") # device configuration\n",
    "\n",
    "# Train the model\n",
    "history = train_model(model, train_loader, val_loader, criterion, optimizer, lr_scheduler, EPOCHS, device)\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS640",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
